apiVersion: v1
kind: ServiceAccount
metadata:
  name: mysql-failover-watcher
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: mysql-failover-role
  namespace: default
rules:
  - apiGroups: [""]
    resources: ["services", "endpoints", "pods"]
    verbs: ["get", "patch", "list", "watch"]
  # Deployment를 제어하기 위한 권한 추가
  - apiGroups: ["apps"]
    resources: ["deployments", "deployments/scale"]
    verbs: ["get", "patch", "list", "watch", "update"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: mysql-failover-binding
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: mysql-failover-role
subjects:
  - kind: ServiceAccount
    name: mysql-failover-watcher
---
# Pod의 api-server 컨테이너로의 외부 접근을 위한 NodePort 서비스
apiVersion: v1
kind: Service
metadata:
  name: failover-api-service
spec:
  type: NodePort
  selector:
    app: mysql-failover-watcher
  ports:
    - protocol: TCP
      port: 8080      # 클러스터 내부에서 사용할 포트
      targetPort: 8080 # Pod의 api-server 컨테이너가 리스닝할 포트
      nodePort: 30888  # 외부에서 접근할 NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql-failover-watcher
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql-failover-watcher
  template:
    metadata:
      labels:
        app: mysql-failover-watcher
    spec:
      hostNetwork: true
      serviceAccountName: mysql-failover-watcher
      volumes:
        - name: state-volume
          emptyDir: {}
        - name: bin-volume
          emptyDir: {}

      initContainers:
        - name: kubectl-downloader
          image: alpine:latest
          command:
            - /bin/sh
            - -c
            - |
              apk update && apk add curl
              curl -LO "https://dl.k8s.io/release/v1.29.0/bin/linux/amd64/kubectl"
              chmod +x kubectl
              mv kubectl /shared-bin/
          volumeMounts:
            - name: bin-volume
              mountPath: /shared-bin

      containers:
        # kubectl-watcher 컨테이너
        - name: kubectl-watcher
          image: alpine:latest
          volumeMounts:
            - name: state-volume
              mountPath: /state
            - name: bin-volume
              mountPath: /shared-bin
          command:
            - /bin/sh
            - -c
            - |
              PREV_LOG_MSG=""
              echo "$(date '+%Y-%m-%d %H:%M:%S') [Watcher] Starting failover watcher."
              echo "active" > /state/state
              while true; do
                EP_ACTIVE=$(/shared-bin/kubectl get pods -l app=mysql-active -o jsonpath='{.items[?(@.status.containerStatuses[0].ready==true)]}' | wc -w)
                CURRENT_SELECTOR=$(/shared-bin/kubectl get svc mysql-active-service -o jsonpath='{.spec.selector.app}')
                if [ -z "$CURRENT_SELECTOR" ]; then
                  echo "$(date '+%Y-%m-%d %H:%M:%S') [Watcher] WARN: mysql-active-service not found. Retrying..."
                  sleep 15
                  continue
                fi
                if [ -f /state/recover_command ]; then
                  echo "$(date '+%Y-%m-%d %H:%M:%S') [Recovery] EVENT: Received recovery command."
                  if [ "$EP_ACTIVE" -gt 0 ]; then
                    if [ "$CURRENT_SELECTOR" = "mysql-standby" ]; then
                      echo "$(date '+%Y-%m-%d %H:%M:%S') [Recovery] EVENT: Active pod is ready. Recovering to active..."
                      /shared-bin/kubectl patch svc mysql-active-service --type=json -p "[{\"op\":\"replace\",\"path\":\"/spec/selector/app\",\"value\":\"mysql-active\"}]"
                      echo "active" > /state/state
                    else
                      echo "$(date '+%Y-%m-%d %H:%M:%S') [Recovery] INFO: Already in active state. No action needed."
                    fi
                  else
                    echo "$(date '+%Y-%m-%d %H:%M:%S') [Recovery] WARN: Recovery failed. Active pod is not ready yet."
                  fi
                  rm /state/recover_command
                elif [ "$EP_ACTIVE" -lt 1 ] && [ "$CURRENT_SELECTOR" = "mysql-active" ]; then
                  echo "$(date '+%Y-%m-%d %H:%M:%S') [Failover] EVENT: Active pod is down. Failing over to standby..."
                  /shared-bin/kubectl patch svc mysql-active-service --type=json -p "[{\"op\":\"replace\",\"path\":\"/spec/selector/app\",\"value\":\"mysql-standby\"}]"
                  echo "standby" > /state/state
                fi
                CURRENT_LOG_MSG="[Watcher] State: $(cat /state/state), Service selector: ${CURRENT_SELECTOR}, ActiveReady: ${EP_ACTIVE}"
                if [ "$CURRENT_LOG_MSG" != "$PREV_LOG_MSG" ]; then
                  echo "$(date '+%Y-%m-%d %H:%M:%S') ${CURRENT_LOG_MSG}"
                  PREV_LOG_MSG="$CURRENT_LOG_MSG"
                fi
                sleep 15
              done

        # api-server 컨테이너에 Active DB 스케일링 기능 추가
        - name: api-server
          image: alpine:latest
          volumeMounts:
            - name: state-volume
              mountPath: /state
            - name: bin-volume
              mountPath: /shared-bin
          command:
            - /bin/sh
            - -c
            - |
              # Changed: Add py3-requests for API calls
              apk update && apk add python3 py3-requests

              python3 -c '
              import http.server
              import socketserver
              import json
              import subprocess
              import os
              import requests # Changed: Import requests

              PORT = 8080
              KUBECTL_PATH = "/shared-bin/kubectl"
              ACTIVE_DB_DEPLOYMENT = "mysql-active"
              DEBEZIUM_DEPLOYMENT = "debezium-server"
              # Changed: Add Ravo-Agent URL (실제 K-PaaS상 RAVO-AGENT의 SVC 주소와 PORT 설정 필요)
              RAVO_AGENT_URL = "http://<RAVO_AGENT_IP>:<RAVO_AGENT_PORT>"

              class ApiHandler(http.server.SimpleHTTPRequestHandler):
                  def _run_command(self, command):
                      return subprocess.run(
                          command, capture_output=True, text=True, check=True
                      )

                  def _send_json_response(self, status_code, data):
                      self.send_response(status_code)
                      self.send_header("Content-type", "application/json")
                      self.end_headers()
                      self.wfile.write(json.dumps(data, ensure_ascii=False).encode("utf-8"))

                  # Changed: Add helper function to call Ravo-Agent
                  def _call_ravo_agent(self, endpoint):
                      try:
                          url = f"{RAVO_AGENT_URL}{endpoint}"
                          response = requests.get(url, timeout=10)
                          response.raise_for_status()
                          return True, response.json()
                      except requests.exceptions.RequestException as e:
                          return False, {"error": str(e)}

                  def do_GET(self):
                      try:
                          if self.path == "/status":
                              self.handle_status()
                          elif self.path == "/scale-down":
                              self.handle_scale_down()
                          elif self.path == "/scale-up":
                              self.handle_scale_up_db()
                          elif self.path == "/recover":
                              self.handle_recover()
                          else:
                              self._send_json_response(404, {"error": "Not Found", "path_detected": self.path})
                      except subprocess.CalledProcessError as e:
                          error_details = {"error": "Command failed", "command": e.cmd, "stdout": e.stdout, "stderr": e.stderr}
                          self._send_json_response(500, error_details)
                      except Exception as e:
                          self._send_json_response(500, {"error": str(e)})

                  def handle_status(self):
                      selector_proc = self._run_command(
                          [KUBECTL_PATH, "get", "svc", "mysql-active-service", "-o", "jsonpath={.spec.selector.app}"]
                      )
                      current_selector = selector_proc.stdout.strip()
                      try:
                          with open("/state/state", "r") as f:
                              internal_state = f.read().strip()
                      except FileNotFoundError:
                          internal_state = "unknown"
                      try:
                          replicas_proc = self._run_command(
                              [KUBECTL_PATH, "get", "deployment", ACTIVE_DB_DEPLOYMENT, "-o", "jsonpath={.spec.replicas},{.status.readyReplicas}"]
                          )
                          desired, ready = replicas_proc.stdout.strip().split(",")
                          mysql_active_replicas = {"desired": int(desired), "ready": int(ready) if ready else 0}
                      except subprocess.CalledProcessError:
                          mysql_active_replicas = {"error": f"Deployment ''{ACTIVE_DB_DEPLOYMENT}'' not found"}
                      try:
                          replicas_proc = self._run_command(
                              [KUBECTL_PATH, "get", "deployment", DEBEZIUM_DEPLOYMENT, "-o", "jsonpath={.spec.replicas},{.status.readyReplicas}"]
                          )
                          desired, ready = replicas_proc.stdout.strip().split(",")
                          debezium_replicas = {"desired": int(desired), "ready": int(ready) if ready else 0}
                      except subprocess.CalledProcessError:
                          debezium_replicas = {"error": f"Deployment ''{DEBEZIUM_DEPLOYMENT}'' not found"}
                      response_body = {
                          "service_target": current_selector,
                          "watcher_state": internal_state,
                          "mysql_active_replicas": mysql_active_replicas,
                          "debezium_replicas": debezium_replicas
                      }
                      self._send_json_response(200, response_body)

                  # /scale-down 기능 - Active DB와 Debezium을 함께 종료
                  def handle_scale_down(self):
                      self._run_command(
                          [KUBECTL_PATH, "scale", "deployment", ACTIVE_DB_DEPLOYMENT, "--replicas=0"]
                      )
                      self._run_command(
                          [KUBECTL_PATH, "scale", "deployment", DEBEZIUM_DEPLOYMENT, "--replicas=0"]
                      )
                      # Changed: Call Ravo-Agent /scale-down
                      success, ra_response = self._call_ravo_agent("/scale-down")
                      if success:
                          message = f"Successfully scaled down ''{ACTIVE_DB_DEPLOYMENT}'' and ''{DEBEZIUM_DEPLOYMENT}'' on-prem and initiated scale down on K-PaaS."
                          self._send_json_response(200, {"message": message, "ravo_agent_response": ra_response})
                      else:
                          message = f"Scaled down local deployments, but failed to call Ravo-Agent."
                          self._send_json_response(502, {"message": message, "ravo_agent_error": ra_response})

                  # /scale-up 기능 - Active DB만 먼저 시작
                  def handle_scale_up_db(self):
                      self._run_command(
                          [KUBECTL_PATH, "scale", "deployment", ACTIVE_DB_DEPLOYMENT, f"--replicas=1"]
                      )
                      # Changed: Call Ravo-Agent /scale-up
                      success, ra_response = self._call_ravo_agent("/scale-up")
                      if success:
                          message = f"Successfully scaled up ''{ACTIVE_DB_DEPLOYMENT}'' on-prem and initiated scale up on K-PaaS. Call /recover after the DB is fully running."
                          self._send_json_response(200, {"message": message, "ravo_agent_response": ra_response})
                      else:
                          message = f"Scaled up local DB, but failed to call Ravo-Agent."
                          self._send_json_response(502, {"message": message, "ravo_agent_error": ra_response})


                  # /recover 기능 - 서비스 전환 요청 및 Debezium 시작
                  def handle_recover(self):
                      with open("/state/recover_command", "w") as f:
                          f.write("recover")
                      # conntrack-watcher에 flush를 요청하기 위한 신호 파일 생성
                      with open("/state/conntrack_flush_request", "w") as f:
                          f.write("flush")
                      self._run_command(
                          [KUBECTL_PATH, "scale", "deployment", DEBEZIUM_DEPLOYMENT, "--replicas=1"]
                      )
                      # Changed: Call Ravo-Agent /recover
                      success, ra_response = self._call_ravo_agent("/recover")
                      if success:
                          message = "Requested service recovery to Active DB and started Debezium on-prem. Initiated recovery on K-PaaS."
                          self._send_json_response(200, {"message": message, "ravo_agent_response": ra_response})
                      else:
                          message = "Performed local recovery actions, but failed to call Ravo-Agent."
                          self._send_json_response(502, {"message": message, "ravo_agent_error": ra_response})

              with socketserver.TCPServer(("", PORT), ApiHandler) as httpd:
                  print("Python API server started at port", PORT)
                  httpd.serve_forever()
              '

        # conntrack-watcher 컨테이너
        - name: conntrack-watcher
          image: docker.io/nicolaka/netshoot:latest
          securityContext:
            capabilities:
              add: ["NET_ADMIN"]
          volumeMounts:
            - name: state-volume
              mountPath: /state
          command:
            - /bin/sh
            - -c
            - |
              PREV_FILE_STATE=""
              while true; do
                if [ -f /state/state ]; then
                  CUR_STATE=$(cat /state/state)
                  # 상태 변경 또는 복구 요청 파일이 있을 경우 conntrack flush 실행
                  if [ "$CUR_STATE" != "$PREV_FILE_STATE" ] || [ -f /state/conntrack_flush_request ]; then
                    conntrack -D -p tcp --dport 32316
                    conntrack -D -p tcp --dport 32317
                    echo "$(date '+%Y-%m-%d %H:%M:%S') Flushed conntrack for 32316, 32317 (state=${CUR_STATE})"
                    rm -f /state/conntrack_flush_request # 처리 후 신호 파일 삭제
                  fi
                  PREV_FILE_STATE="$CUR_STATE"
                fi
                sleep 5
              done